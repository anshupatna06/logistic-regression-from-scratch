# ğŸš¢ Titanic Survival Prediction â€” Logistic Regression from Scratch

This repository contains a custom implementation of **Logistic Regression** from scratch (without scikit-learn), applied to the Titanic dataset. It includes performance evaluation using various classification metrics.

"ML models implemented from scratch using NumPy and Pandas only"
# Logistic Regression from Scratch ğŸ§ 

This project implements **Logistic Regression** from scratch using **NumPy**, without using any ML libraries like scikit-learn.

## ğŸš€ Whatâ€™s Inside

- âœ… Sigmoid function
- âœ… Binary Cross-Entropy Loss
- âœ… Gradient Descent Optimization
- âœ… Prediction & Accuracy Calculation
- âœ… Tested on the **Titanic Dataset**

- ### ğŸ§ª Evaluation Metrics Included:
- âœ… Confusion Matrix
- âœ… Precision
- âœ… Recall
- âœ… F1-Score
- âœ… ROC Curve
- âœ… AUC Score

- ## ğŸ“ˆ Evaluation Highlights (Sample Output)

| Metric            | Value       |
|-------------------|-------------|
| Accuracy          | 0.79        |
| Precision         | 0.84        |
| Recall            | 0.83        |
| F1-Score          | 0.83        |
| AUC Score         | 0.86        |

ğŸ“Š ROC Curve and Confusion Matrix are visualized using Matplotlib.

## ğŸ“Š Dataset

- Dataset: [Kaggle Titanic Dataset](https://www.kaggle.com/competitions/titanic/data)
- Features used: `Pclass`, `Sex`, `Age`, `SibSp`, `Fare`

## ğŸ“ˆ Results

- Final Training Accuracy: ~80%
- Loss decreased with iterations (graph included in notebook)

- ## ğŸš§ Future Improvements

-More better contents with full "Explanation" and "Logic" behind using everything in the priject 
- Implementation of Mathematical Calculations "Manually" without using libraries like Scikit-Learn (from scratch)
- Feature importance visualization
- 
- Deployment with Streamlit

- ## ğŸ™‹â€â™‚ï¸ Author

- **Anshu Pandey**
- GitHub: [anshupatna06](https://github.com/anshupatna06)

## ğŸ“ License

This project is licensed under the MIT License.
## ğŸ“ Project Structure
